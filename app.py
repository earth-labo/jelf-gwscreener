"""
ClimateWashè¨ºæ–­ãƒ„ãƒ¼ãƒ« - å…¨æ©Ÿèƒ½çµ±åˆç‰ˆï¼ˆYouTubeå®‰å…¨ãƒ¢ãƒ¼ãƒ‰ï¼‹Whisperæ–‡å­—èµ·ã“ã—å¯¾å¿œï¼‰
"""
import streamlit as st
import sys
import os
from datetime import datetime
import json
import re
import tempfile
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound

# è‡ªåˆ†ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.ai_handler import AIHandler
from modules.evaluator import evaluate_result, format_result_for_display, calculate_score
from modules.text_analyzer import analyze_text_content, quick_check_text
from modules.image_analyzer import analyze_image_content, get_image_info
from modules.pdf_analyzer import analyze_pdf_content, get_pdf_info
from modules.web_analyzer import analyze_web_content, get_web_info
from modules.sheets_exporter import SheetsExporter, load_credentials_from_streamlit_secrets
from modules.pdf_reporter import generate_pdf_report
from config.criteria import VERSIONS, get_criteria_sections, EXAMPLE_LIBRARY

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ClimateWashè¨ºæ–­ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if "diagnosis_history" not in st.session_state:
    st.session_state.diagnosis_history = []
if "current_result" not in st.session_state:
    st.session_state.current_result = None


# -----------------------------
# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -----------------------------
def load_system_prompt():
    prompt_path = os.path.join(os.path.dirname(__file__), "prompts", "system_prompt.txt")
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read()


def extract_youtube_id(url: str):
    """ã„ã‚ã„ã‚ãªå½¢å¼ã® YouTube URL ã‹ã‚‰ video_id ã‚’æŠœãå‡ºã™"""
    patterns = [
        r"v=([A-Za-z0-9_-]{11})",
        r"youtu\.be/([A-Za-z0-9_-]{11})",
        r"youtube\.com/embed/([A-Za-z0-9_-]{11})",
    ]
    for p in patterns:
        m = re.search(p, url)
        if m:
            return m.group(1)
    return None


def fetch_youtube_subtitles(video_id: str):
    """
    YouTube å­—å¹•å–å¾—
    - æ—¥æœ¬èªè‡ªå‹• â†’ æ—¥æœ¬èªæ‰‹å‹• â†’ è‹±èªè‡ªå‹• â†’ è‹±èªæ‰‹å‹• ã®é †ã§æ¢ã™
    """
    try:
        transcripts = YouTubeTranscriptApi.list_transcripts(video_id)

        # æ—¥æœ¬èªï¼ˆè‡ªå‹•ï¼‰
        try:
            t = transcripts.find_generated_transcript(['ja']).fetch()
            return " ".join(x["text"] for x in t)
        except Exception:
            pass

        # æ—¥æœ¬èªï¼ˆæ‰‹å‹•ï¼‰
        try:
            t = transcripts.find_manually_created_transcript(['ja']).fetch()
            return " ".join(x["text"] for x in t)
        except Exception:
            pass

        # è‹±èªï¼ˆè‡ªå‹•ï¼‰
        try:
            t = transcripts.find_generated_transcript(['en']).fetch()
            return " ".join(x["text"] for x in t)
        except Exception:
            pass

        # è‹±èªï¼ˆæ‰‹å‹•ï¼‰
        try:
            t = transcripts.find_manually_created_transcript(['en']).fetch()
            return " ".join(x["text"] for x in t)
        except Exception:
            pass

        return None

    except (TranscriptsDisabled, NoTranscriptFound):
        return None
    except Exception:
        return None


def transcribe_video_with_openai(video_bytes: bytes, api_key: str):
    """
    Whisperï¼ˆæ–°ã—ã„ openai-pythonï¼‰ã§å‹•ç”»ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹ã€‚
    GPT-4ç³»ï¼ˆOpenAIãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’é¸æŠã—ãŸæ™‚ã®ã¿åˆ©ç”¨ã™ã‚‹æƒ³å®šã€‚
    """
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(video_bytes)
            tmp_path = tmp.name

        try:
            with open(tmp_path, "rb") as f:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    response_format="text"
                )
            return str(transcript)
        finally:
            os.remove(tmp_path)

    except Exception:
        return None


# -----------------------------
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
# -----------------------------
def main():
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div style='text-align: center; padding: 20px; background: linear-gradient(90deg, #2E7D32 0%, #43A047 100%); border-radius: 10px;'>
        <h1 style='color: white; margin: 0;'>ğŸŒ ClimateWashè¨ºæ–­ãƒ„ãƒ¼ãƒ«</h1>
        <p style='color: white; margin: 10px 0 0 0;'>EUæŒ‡ä»¤æº–æ‹  AIè‡ªå‹•è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ </p>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.markdown("## âš™ï¸ è¨­å®š")

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_type = st.radio(
            "ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«",
            ["Claude (Sonnet 4.5)", "ChatGPT (GPT-4)"],
        )
        model_key = "claude" if "Claude" in model_type else "openai"

        # APIã‚­ãƒ¼
        api_key = None
        if model_key == "claude":
            api_key = st.secrets.get("ANTHROPIC_API_KEY")
        else:
            api_key = st.secrets.get("OPENAI_API_KEY")
        if not api_key:
            api_key = st.text_input("API Key", type="password")

        st.markdown("---")

        # æŒ‡ä»¤è¨­å®š
        green_claims_directive = st.checkbox("ã‚°ãƒªãƒ¼ãƒ³ã‚¯ãƒ¬ãƒ¼ãƒ æŒ‡ä»¤æ¡ˆï¼ˆæ¨å¥¨ï¼‰", value=True)
        directive_label = "ä¸¡æŒ‡ä»¤" if green_claims_directive else "ã‚¨ãƒ³ãƒ‘ãƒ¯ãƒ¡ãƒ³ãƒˆæŒ‡ä»¤ã®ã¿"

        st.markdown("---")

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        version_options = {
            "v1": VERSIONS["v1"]["name"],
            "v2": VERSIONS["v2"]["name"],
            "v3": VERSIONS["v3"]["name"],
        }
        selected_version = st.radio(
            "è¨ºæ–­åŸºæº–ãƒãƒ¼ã‚¸ãƒ§ãƒ³",
            list(version_options.keys()),
            index=2,
            format_func=lambda x: version_options[x],
        )

        st.markdown("---")

        # Sheetsè¨­å®š
        with st.expander("ğŸ“Š Google Sheetsè¨­å®šï¼ˆä»»æ„ï¼‰"):
            spreadsheet_id = st.text_input("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID")
            worksheet_name = st.text_input("ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå", value="è¨ºæ–­çµæœ")

        st.markdown("---")

        # å±¥æ­´ / ä¾‹æ–‡
        if st.button("ğŸ“Š è¨ºæ–­å±¥æ­´ã‚’è¦‹ã‚‹"):
            st.session_state.show_history = True
        if st.button("ğŸ’¡ è¡¨ç¾ä¾‹ã‚’è¦‹ã‚‹"):
            st.session_state.show_examples = True

    # ä¾‹æ–‡
    if st.session_state.get("show_examples", False):
        show_example_library()
        if st.button("é–‰ã˜ã‚‹"):
            st.session_state.show_examples = False
        return

    # å±¥æ­´
    if st.session_state.get("show_history", False):
        show_diagnosis_history()
        if st.button("é–‰ã˜ã‚‹"):
            st.session_state.show_history = False
        return

    # ã‚¿ãƒ–
    tabs = st.tabs([
        "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ",
        "ğŸ–¼ï¸ ç”»åƒ",
        "ğŸ“„ PDF",
        "ğŸ¬ å‹•ç”»ï¼ˆYouTubeï¼‹ãƒ­ãƒ¼ã‚«ãƒ«å®‰å…¨ãƒ¢ãƒ¼ãƒ‰ï¼‰",
        "ğŸŒ Webã‚µã‚¤ãƒˆ"
    ])

    system_prompt = load_system_prompt()
    criteria_sections = get_criteria_sections(selected_version, green_claims_directive)

    with tabs[0]:
        handle_text_analysis(api_key, model_key, system_prompt, criteria_sections,
                             selected_version, directive_label,
                             spreadsheet_id, worksheet_name)

    with tabs[1]:
        handle_image_analysis(api_key, model_key, system_prompt, criteria_sections,
                              selected_version, directive_label,
                              spreadsheet_id, worksheet_name)

    with tabs[2]:
        handle_pdf_analysis(api_key, model_key, system_prompt, criteria_sections,
                            selected_version, directive_label,
                            spreadsheet_id, worksheet_name)

    with tabs[3]:
        handle_video_safe(api_key, model_key, system_prompt, criteria_sections,
                          selected_version, directive_label,
                          spreadsheet_id, worksheet_name)

    with tabs[4]:
        handle_web_analysis(api_key, model_key, system_prompt, criteria_sections,
                            selected_version, directive_label,
                            spreadsheet_id, worksheet_name)


# -----------------------------
# å„è¨ºæ–­ãƒãƒ³ãƒ‰ãƒ©
# -----------------------------
def handle_text_analysis(api_key, model_key, system_prompt, criteria_sections,
                         version, directive_label, spreadsheet_id, worksheet_name):
    st.markdown("### ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆè¨ºæ–­")

    text_input = st.text_area(
        "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›",
        height=200,
        placeholder="ä¾‹ï¼šå½“ç¤¾ã®è£½å“ã¯ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã§ã™â€¦"
    )

    # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
    if text_input and len(text_input) > 10:
        with st.expander("âš¡ ã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“è¨ºæ–­ï¼‰"):
            quick_result = quick_check_text(text_input)
            if quick_result["has_issues"]:
                st.warning(f"âš ï¸ {quick_result['issue_count']} ç¨®é¡ã®æ½œåœ¨çš„å•é¡Œã‚’æ¤œå‡º")
                for issue in quick_result["issues"]:
                    st.markdown(f"**{issue['type']}**: {', '.join(issue['phrases'])}")
                    st.caption(f"ğŸ’¡ {issue['suggestion']}")
            else:
                st.success("æ˜ã‚‰ã‹ãªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆè©³ç´°åˆ†ææ¨å¥¨ï¼‰")

    col1, col2 = st.columns([1, 4])
    with col1:
        btn = st.button("ğŸ” è¨ºæ–­é–‹å§‹", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            st.rerun()

    if not btn:
        return

    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    if not text_input or len(text_input) < 10:
        st.error("10æ–‡å­—ä»¥ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    with st.spinner("AIåˆ†æä¸­â€¦"):
        try:
            ai_handler = AIHandler(model_key, api_key)
            ai_response = analyze_text_content(
                ai_handler, text_input, system_prompt, criteria_sections
            )
            result = evaluate_result(ai_response)
            result["content_type"] = "ãƒ†ã‚­ã‚¹ãƒˆ"
            result["version"] = version
            result["directives"] = directive_label
            result["content_sample"] = text_input[:200]

            st.session_state.current_result = result
            st.session_state.diagnosis_history.append({
                "timestamp": datetime.now(),
                "type": "ãƒ†ã‚­ã‚¹ãƒˆ",
                "result": result,
            })
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return

    display_result(result, spreadsheet_id, worksheet_name)


def handle_image_analysis(api_key, model_key, system_prompt, criteria_sections,
                          version, directive_label, spreadsheet_id, worksheet_name):
    st.markdown("### ğŸ–¼ï¸ ç”»åƒè¨ºæ–­")

    uploaded_file = st.file_uploader(
        "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«",
        type=["png", "jpg", "jpeg", "webp"],
        label_visibility="collapsed"
    )

    if not uploaded_file:
        return

    st.image(uploaded_file, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_container_width=True)
    image_data = uploaded_file.read()
    info = get_image_info(image_data)

    if "error" not in info:
        st.markdown("**ç”»åƒæƒ…å ±:**")
        st.write(f"- ã‚µã‚¤ã‚º: {info['width']} Ã— {info['height']}")
        st.write(f"- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {info['format']}")
        st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {info['size_kb']:.1f} KB")

    col1, col2 = st.columns([1, 4])
    with col1:
        btn = st.button("ğŸ” è¨ºæ–­", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            st.rerun()

    if not btn:
        return

    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    with st.spinner("AIåˆ†æä¸­â€¦"):
        try:
            ai_handler = AIHandler(model_key, api_key)
            ai_response = analyze_image_content(
                ai_handler, image_data, system_prompt, criteria_sections
            )
            result = evaluate_result(ai_response)
            result["content_type"] = "ç”»åƒ"
            result["version"] = version
            result["directives"] = directive_label
            result["content_sample"] = f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}"

            st.session_state.current_result = result
            st.session_state.diagnosis_history.append({
                "timestamp": datetime.now(),
                "type": "ç”»åƒ",
                "result": result,
            })
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return

    display_result(result, spreadsheet_id, worksheet_name)


def handle_pdf_analysis(api_key, model_key, system_prompt, criteria_sections,
                        version, directive_label, spreadsheet_id, worksheet_name):
    st.markdown("### ğŸ“„ PDFè¨ºæ–­")

    uploaded_file = st.file_uploader(
        "PDFãƒ•ã‚¡ã‚¤ãƒ«",
        type=["pdf"],
        label_visibility="collapsed"
    )

    if not uploaded_file:
        return

    pdf_data = uploaded_file.read()
    info = get_pdf_info(pdf_data)

    if "error" not in info:
        st.markdown("**PDFæƒ…å ±:**")
        st.write(f"- ãƒšãƒ¼ã‚¸æ•°: {info['page_count']}")
        st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {info['size_kb']:.1f} KB")

    col1, col2 = st.columns([1, 4])
    with col1:
        btn = st.button("ğŸ” è¨ºæ–­", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            st.rerun()

    if not btn:
        return

    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    with st.spinner("AIåˆ†æä¸­â€¦"):
        try:
            ai_handler = AIHandler(model_key, api_key)
            ai_response = analyze_pdf_content(
                ai_handler, pdf_data, system_prompt, criteria_sections
            )
            result = evaluate_result(ai_response)
            result["content_type"] = "PDF"
            result["version"] = version
            result["directives"] = directive_label
            result["content_sample"] = f"PDFãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}"

            st.session_state.current_result = result
            st.session_state.diagnosis_history.append({
                "timestamp": datetime.now(),
                "type": "PDF",
                "result": result,
            })
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return

    display_result(result, spreadsheet_id, worksheet_name)


def handle_web_analysis(api_key, model_key, system_prompt, criteria_sections,
                        version, directive_label, spreadsheet_id, worksheet_name):
    st.markdown("### ğŸŒ Webã‚µã‚¤ãƒˆè¨ºæ–­")

    url_input = st.text_input(
        "URL",
        placeholder="https://example.com/sustainability",
    )

    if not url_input:
        return

    if not url_input.startswith(("http://", "https://")):
        st.warning("URLã¯ http:// ã¾ãŸã¯ https:// ã§å§‹ã‚ã¦ãã ã•ã„")
        return

    with st.expander("ğŸ” ã‚µã‚¤ãƒˆæƒ…å ±ã‚’ç¢ºèª"):
        with st.spinner("æƒ…å ±å–å¾—ä¸­â€¦"):
            info = get_web_info(url_input)
            if "error" not in info:
                st.markdown(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {info['title']}")
                st.markdown(f"**èª¬æ˜:** {info['description'][:200]}...")
                st.markdown(f"**ãƒ†ã‚­ã‚¹ãƒˆé‡:** {info['text_length']} æ–‡å­—")
                st.markdown(f"**ç”»åƒæ•°:** {info['image_count']} æš")
            else:
                st.error(info["error"])

    col1, col2 = st.columns([1, 4])
    with col1:
        btn = st.button("ğŸ” è¨ºæ–­", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            st.rerun()

    if not btn:
        return

    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    with st.spinner("AIåˆ†æä¸­â€¦"):
        try:
            ai_handler = AIHandler(model_key, api_key)
            ai_response = analyze_web_content(
                ai_handler, url_input, system_prompt, criteria_sections
            )
            result = evaluate_result(ai_response)
            result["content_type"] = "Webã‚µã‚¤ãƒˆ"
            result["version"] = version
            result["directives"] = directive_label
            result["content_sample"] = url_input

            st.session_state.current_result = result
            st.session_state.diagnosis_history.append({
                "timestamp": datetime.now(),
                "type": "Webã‚µã‚¤ãƒˆ",
                "result": result,
            })
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return

    display_result(result, spreadsheet_id, worksheet_name)


def handle_video_safe(api_key, model_key, system_prompt, criteria_sections,
                      version, directive_label, spreadsheet_id, worksheet_name):
    st.markdown("### ğŸ¬ å‹•ç”»è¨ºæ–­ï¼ˆYouTubeï¼‹ãƒ­ãƒ¼ã‚«ãƒ«å®‰å…¨ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    st.markdown("YouTubeå‹•ç”»ã¯åŸ‹ã‚è¾¼ã¿ï¼‹å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆã€ãƒ­ãƒ¼ã‚«ãƒ«å‹•ç”»ã¯Whisperæ–‡å­—èµ·ã“ã—ã§åˆ†æã—ã¾ã™ã€‚")

    tab_url, tab_file = st.tabs(["ğŸ¥ YouTube URL ã‹ã‚‰åˆ†æ", "ğŸ“ æ‰‹å…ƒã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åˆ†æ"])

    transcript_source_label = None

    # --- YouTube ã‚¿ãƒ– ---
    with tab_url:
        youtube_url = st.text_input(
            "YouTubeã®URL",
            placeholder="https://www.youtube.com/watch?v=XXXXXXX"
        )

        video_id = None
        if youtube_url:
            video_id = extract_youtube_id(youtube_url)
            if not video_id:
                st.error("YouTube URL ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                embed_url = f"https://www.youtube.com/embed/{video_id}"
                st.markdown("#### â–¶ å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.video(embed_url)
                transcript_source_label = f"YouTube: {youtube_url}"

        st.markdown("---")

        # å­—å¹•è‡ªå‹•å–å¾—
        if video_id and st.button("ğŸ¯ YouTubeå­—å¹•ã‚’è‡ªå‹•å–å¾—ã™ã‚‹", type="primary"):
            with st.spinner("å­—å¹•ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™..."):
                auto_caption = fetch_youtube_subtitles(video_id)
            if auto_caption:
                st.success("å­—å¹•ã‚’å–å¾—ã—ã¾ã—ãŸ")
                st.session_state["auto_caption"] = auto_caption
            else:
                st.error("åˆ©ç”¨å¯èƒ½ãªå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # --- ãƒ­ãƒ¼ã‚«ãƒ«å‹•ç”»ã‚¿ãƒ– ---
    with tab_file:
        uploaded_file = st.file_uploader(
            "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmp4, mov, m4a, mp3, wavãªã©ï¼‰",
            type=["mp4", "mov", "m4a", "mp3", "wav"],
            help="æœ€å¤§æ•°åˆ†ç¨‹åº¦ã¾ã§ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
        )

        if uploaded_file:
            try:
                st.video(uploaded_file)
            except Exception:
                st.caption("ã“ã®å½¢å¼ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")

            st.markdown("#### ğŸ”Š è‡ªå‹•æ–‡å­—èµ·ã“ã—ï¼ˆWhisperï¼‰")

            if model_key != "openai":
                st.info("è‡ªå‹•æ–‡å­—èµ·ã“ã—ã¯ ChatGPT (GPT-4) é¸æŠæ™‚ã®ã¿åˆ©ç”¨ã§ãã¾ã™ã€‚")
            else:
                if st.button("ğŸ¯ ã“ã®å‹•ç”»ã‹ã‚‰æ–‡å­—èµ·ã“ã—ã™ã‚‹", key="transcribe_local_video"):
                    uploaded_file.seek(0)
                    video_bytes = uploaded_file.read()
                    with st.spinner("Whisper ã§æ–‡å­—èµ·ã“ã—ä¸­â€¦"):
                        text = transcribe_video_with_openai(video_bytes, api_key)
                    if text:
                        st.success("æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸ")
                        st.session_state["auto_caption"] = text
                        transcript_source_label = f"ãƒ­ãƒ¼ã‚«ãƒ«å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}"
                    else:
                        st.error("æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- å…±é€šï¼šãƒ†ã‚­ã‚¹ãƒˆç·¨é›†ï¼†è¨ºæ–­ ---
    st.markdown("---")
    st.subheader("ğŸ“ å­—å¹• / èª¬æ˜æ–‡ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ç·¨é›†å¯ï¼‰")

    caption_text = st.text_area(
        "å­—å¹•ãƒ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ»èª¬æ˜æ–‡",
        value=st.session_state.get("auto_caption", ""),
        height=250,
        placeholder="YouTubeå­—å¹•ã€è‡ªå‹•æ–‡å­—èµ·ã“ã—çµæœã€ã¾ãŸã¯è‡ªåˆ†ã§ç”¨æ„ã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„"
    )

    col1, col2 = st.columns([1, 4])
    with col1:
        btn = st.button("ğŸ” è¨ºæ–­é–‹å§‹", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            st.session_state["auto_caption"] = ""
            st.rerun()

    if not btn:
        return

    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    if not caption_text.strip():
        st.error("å­—å¹•ã¾ãŸã¯èª¬æ˜æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    with st.spinner("AI ãŒãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’åˆ†æä¸­ã§ã™â€¦"):
        try:
            ai_handler = AIHandler(model_key, api_key)
            ai_response = analyze_text_content(
                ai_handler, caption_text, system_prompt, criteria_sections
            )

            result = evaluate_result(ai_response)
            result["content_type"] = "å‹•ç”»ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆå­—å¹•ãƒ»æ–‡å­—èµ·ã“ã—ï¼‰"
            result["version"] = version
            result["directives"] = directive_label
            result["content_sample"] = caption_text[:200]
            if transcript_source_label:
                result["source"] = transcript_source_label

            st.session_state.current_result = result
            st.session_state.diagnosis_history.append({
                "timestamp": datetime.now(),
                "type": "å‹•ç”»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
                "result": result,
            })
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return

    display_result(result, spreadsheet_id, worksheet_name)


# -----------------------------
# çµæœè¡¨ç¤ºãƒ»å±¥æ­´ãƒ»ä¾‹æ–‡
# -----------------------------
def display_result(result, spreadsheet_id, worksheet_name):
    st.markdown("---")
    st.markdown("## ğŸ“Š è¨ºæ–­çµæœ")

    if not result.get("success", False):
        st.error(f"âŒ {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        if "details" in result:
            st.error(result["details"])
        return

    risk_info = result.get("risk_info", {})
    color = risk_info.get("color", "")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç·åˆè©•ä¾¡", f"{color} {result['overall_risk']}")
    with col2:
        st.metric("ã‚¹ã‚³ã‚¢", f"{result['score']}/100")
    with col3:
        st.metric("é•åé …ç›®æ•°", f"{len(result['violations'])}ä»¶")

    st.info(f"ğŸ“ {risk_info.get('description', '')}")

    formatted = format_result_for_display(result)
    st.markdown(formatted)

    col1, col2, col3 = st.columns(3)

    # PDF
    with col1:
        try:
            pdf_data = generate_pdf_report(result)
            st.download_button(
                "ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=pdf_data,
                file_name=f"climatewash_report_{datetime.now():%Y%m%d_%H%M%S}.pdf",
                mime="application/pdf",
                use_container_width=True,
            )
        except Exception as e:
            st.error(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # JSON
    with col2:
        json_data = json.dumps(result, ensure_ascii=False, indent=2)
        st.download_button(
            "ğŸ“¥ JSONçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json_data,
            file_name=f"climatewash_result_{datetime.now():%Y%m%d_%H%M%S}.json",
            mime="application/json",
            use_container_width=True,
        )

    # Google Sheets
    with col3:
        if spreadsheet_id and worksheet_name:
            if st.button("ğŸ“Š Google Sheetsã«å‡ºåŠ›", use_container_width=True):
                try:
                    creds = load_credentials_from_streamlit_secrets(st)
                    if creds:
                        exporter = SheetsExporter(creds)
                        ok = exporter.export_results(spreadsheet_id, worksheet_name, result)
                        if ok:
                            st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å‡ºåŠ›ã—ã¾ã—ãŸ")
                        else:
                            st.error("å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    else:
                        st.error("Googleèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.caption("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå‡ºåŠ›ã«ã¯IDã¨ã‚·ãƒ¼ãƒˆåã®è¨­å®šãŒå¿…è¦ã§ã™")


def show_example_library():
    st.markdown("## ğŸ’¡ é©åˆ‡ãªè¡¨ç¾ä¾‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
    st.markdown("EUæŒ‡ä»¤ã«æº–æ‹ ã—ãŸé©åˆ‡ãªè¡¨ç¾ä¾‹ã‚’å‚ç…§ã§ãã¾ã™ã€‚")

    for category, examples in EXAMPLE_LIBRARY.items():
        with st.expander(f"ğŸ“š {category}"):
            for i, example in enumerate(examples, 1):
                st.markdown(f"### ä¾‹ {i}")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**âŒ NGè¡¨ç¾:**")
                    st.error(example["ng"])
                with col2:
                    st.markdown("**âœ… OKè¡¨ç¾:**")
                    st.success(example["ok"])

                st.markdown(f"**ğŸ“ ç†ç”±:** {example['reason']}")
                st.markdown("---")


def show_diagnosis_history():
    st.markdown("## ğŸ“Š è¨ºæ–­å±¥æ­´")

    history = st.session_state.diagnosis_history
    if not history:
        st.info("ã¾ã è¨ºæ–­å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    history = sorted(history, key=lambda x: x["timestamp"], reverse=True)

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·è¨ºæ–­æ•°", len(history))
    with col2:
        avg_score = sum(h["result"]["score"] for h in history) / len(history)
        st.metric("å¹³å‡ã‚¹ã‚³ã‚¢", f"{avg_score:.1f}")
    with col3:
        high_risk_count = sum(1 for h in history if h["result"]["overall_risk"] == "High Risk")
        st.metric("High Riskä»¶æ•°", high_risk_count)
    with col4:
        type_counts = {}
        for h in history:
            t = h["type"]
            type_counts[t] = type_counts.get(t, 0) + 1
        most_common = max(type_counts.items(), key=lambda x: x[1])[0]
        st.metric("æœ€å¤šè¨ºæ–­ã‚¿ã‚¤ãƒ—", most_common)

    st.markdown("---")
    st.markdown("### ğŸ“‹ è¨ºæ–­ãƒªã‚¹ãƒˆ")

    for entry in history:
        ts = entry["timestamp"].strftime("%Y-%m-%d %H:%M:%S")
        r = entry["result"]
        with st.expander(f"{ts} - {entry['type']} - {r['overall_risk']} ({r['score']}ç‚¹)"):
            st.markdown(format_result_for_display(r))


if __name__ == "__main__":
    main()
